{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "D:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:34: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image/dataset_medium/COAD_01/scale-25pc/S6.jpg\n",
      "image/dataset_medium/COAD_01/scale-25pc/S6.jpg\n"
     ]
    }
   ],
   "source": [
    "source_image_array= []\n",
    "target_image_array= []\n",
    "source_image_landmarks= []\n",
    "target_image_landmarks= []\n",
    "\n",
    "def read_csv_file():\n",
    "\n",
    "\n",
    "    DATASET_MEDIUM_DIR = 'dataset_medium.csv'\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "    \n",
    "    \n",
    "    imgs_dirs = []\n",
    "    dataset_read_result = pd.read_csv(DATASET_MEDIUM_DIR)\n",
    "    i = 0\n",
    "    for each_img_dir, \\\n",
    "        each_landmarks_dir, \\\n",
    "        each_target_image, \\\n",
    "        each_target_landmarks, \\\n",
    "        each_status in zip(dataset_read_result['Source image'],\n",
    "                           dataset_read_result['Source landmarks'],\n",
    "                           dataset_read_result['Target image'],\n",
    "                           dataset_read_result['Target landmarks'],\n",
    "                           dataset_read_result['status']):\n",
    "        if each_status=='training':\n",
    "            each_img_dir = 'image/dataset_medium/' + each_img_dir\n",
    "            each_landmarks_dir = 'landmark/' + each_landmarks_dir\n",
    "            each_target_image = 'image/dataset_medium/' + each_target_image\n",
    "            each_target_landmarks = 'landmark/' + each_target_landmarks\n",
    "\n",
    "            dataset_read_result.set_value(index=i, col='Source image', value=each_img_dir)\n",
    "            dataset_read_result.set_value(index=i, col='Source landmarks', value=each_landmarks_dir)\n",
    "            dataset_read_result.set_value(index=i, col='Target image', value=each_target_image)\n",
    "            dataset_read_result.set_value(index=i, col='Target landmarks', value=each_target_landmarks)\n",
    "            \n",
    "            ######################################\n",
    "            source_image_array.append(each_img_dir)\n",
    "            target_image_array.append(each_target_image)\n",
    "            source_image_landmarks.append(each_landmarks_dir)\n",
    "            target_image_landmarks.append(each_target_landmarks)\n",
    "            ##########################\n",
    "            imgs_dirs.append(each_img_dir)\n",
    "            i = i + 1\n",
    "\n",
    "    print(dataset_read_result['Source image'][1])\n",
    "    print(imgs_dirs[1])\n",
    "    return dataset_read_result\n",
    "\n",
    "\n",
    "dataset_read_result = read_csv_file()\n",
    "\n",
    "# the first 10\n",
    "# source_image_array = dataset_read_result['Source image']\n",
    "# target_image_array = dataset_read_result['Target image']\n",
    "# source_image_landmarks = dataset_read_result['Source landmarks']\n",
    "# target_image_landmarks = dataset_read_result['Target landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class matchNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        #使用super()方法调用基类的构造器，即nn.Module.__init__(self)\n",
    "        super(matchNet,self).__init__()\n",
    "        \n",
    "        \n",
    "        ## note here wantna to combined two image together\n",
    "        self.conv_0 = nn.Conv2d(3, 32, kernel_size=2)\n",
    "        self.pool_0 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(64, 128, kernel_size=2, stride=1)\n",
    "#         self.conv_3 = nn.Conv2d(128, 128, kernel_size=2, stride=1)\n",
    "#         self.conv_4 = nn.Conv2d(128, 64, kernel_size=2, stride=1)\n",
    "        self.pool_4 = torch.nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        \n",
    "        \n",
    "        # input based on previous , output choose from 128, 256, 512\n",
    "        self.bottleNeck = torch.nn.Linear(128, 512)\n",
    "        \n",
    "        # FC layers, input based on the previous, output choose from 128, 256, 512, 1024\n",
    "        # this layer with the softmax\n",
    "        self.fc_1 = torch.nn.Linear(1024, 256)\n",
    "        self.fc_2 = torch.nn.Linear(256, 128)\n",
    "        self.fc_3 = torch.nn.Linear(128, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        x = F.relu(self.conv_0(x))\n",
    "        x = self.pool_0(x) \n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.pool_1(x) \n",
    "        x = F.relu(self.conv_2(x))\n",
    "#         x = F.relu(self.conv_3(x))\n",
    "#         x = F.relu(self.conv_4(x))\n",
    "        x = self.pool_4(x)\n",
    "        \n",
    "        x = x.view(-1, 128)\n",
    "        x = F.relu(self.bottleNeck(x))\n",
    "        ########################\n",
    "        \n",
    "        y = F.relu(self.conv_0(y))\n",
    "        y = self.pool_0(y) \n",
    "        y = F.relu(self.conv_1(y))\n",
    "        y = self.pool_1(y) \n",
    "        y = F.relu(self.conv_2(y))\n",
    "#         y = F.relu(self.conv_3(y))\n",
    "#         y = F.relu(self.conv_4(y))\n",
    "        y = self.pool_4(y)\n",
    "        \n",
    "        y = y.view(-1, 128)\n",
    "        y = F.relu(self.bottleNeck(y))\n",
    "        #########################\n",
    "        \n",
    "        output =torch.cat((x, y),1)\n",
    "        \n",
    "        output =self.dropout(F.relu(self.fc_1(output))) \n",
    "            \n",
    "        output = self.dropout(F.relu(self.fc_2(output)))\n",
    "        output = self.sigmoid(self.fc_3(output))\n",
    "        \n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First using the SIFT to get the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "imgname1 = source_image_array[1]\n",
    "imgname2 = target_image_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_ratio = 50\n",
    "\n",
    "img1 = cv2.imread(imgname1)\n",
    "height1, width1, channels = img1.shape\n",
    "img2 = cv2.imread(imgname2)\n",
    "height2, width2, channels = img2.shape\n",
    "\n",
    "height1_resize = int(height1/scaling_ratio)\n",
    "width1_resize = int(width1/scaling_ratio)\n",
    "\n",
    "# print(height1) # 16308\n",
    "# print(height1_resize) #326\n",
    "\n",
    "\n",
    "height2_resize = int(height2/scaling_ratio)\n",
    "width2_resize = int(width2/scaling_ratio)\n",
    "\n",
    "# print(height2) # 13812\n",
    "# print(height2_resize) #276\n",
    "\n",
    "height_max = max(height1_resize, height2_resize)\n",
    "width_max = max(width1_resize, width2_resize )\n",
    "\n",
    "# print(height_max) # 326\n",
    "\n",
    "height1_resize_add_pad = int((height_max - height1_resize)/2)\n",
    "width1_resize_add_pad = int((width_max - width1_resize)/2)\n",
    "\n",
    "height2_resize_add_pad = int((height_max - height2_resize)/2)\n",
    "width2_resize_add_pad = int((width_max - width2_resize)/2)\n",
    "\n",
    "\n",
    "img1 = cv2.resize(img1, (width1_resize,height1_resize))\n",
    "img2 = cv2.resize(img2, (width2_resize,height2_resize))\n",
    "\n",
    "\n",
    "color = [255, 255, 255]\n",
    "image1 = cv2.copyMakeBorder(img1, height1_resize_add_pad, height1_resize_add_pad, width1_resize_add_pad, width1_resize_add_pad,cv2.BORDER_CONSTANT, value = color)\n",
    "image2 = cv2.copyMakeBorder(img2, height2_resize_add_pad, height2_resize_add_pad, width2_resize_add_pad, width2_resize_add_pad,cv2.BORDER_CONSTANT, value = color)\n",
    "image1 = cv2.resize(image1, (width_max,height_max))\n",
    "image1 = cv2.resize(image1, (width_max,height_max))\n",
    "height1, width1, channels = image1.shape\n",
    "height2, width2, channels = image2.shape\n",
    "\n",
    "\n",
    "# hmerge = np.hstack((image1, image2)) #水平拼接\n",
    "# plt.imshow(hmerge,cmap='gray')#拼接显示为gray\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1, des1 = sift.detectAndCompute(image1,None)#des是描述子\n",
    "kp2, des2 = sift.detectAndCompute(image2,None)\n",
    "img3 = cv2.drawKeypoints(image1,kp1,image1,color=(255,0,255))\n",
    "img4 = cv2.drawKeypoints(image2,kp2,image2,color=(255,0,255))\n",
    "\n",
    "# hmerge = np.hstack((img3, img4)) #水平拼接\n",
    "# plt.imshow(hmerge)#拼接显示为gray\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化 keypoint to point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.571414947509766"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp1[0].pt\n",
    "kp1[0].pt[0] # x\n",
    "kp1[0].pt[1] # y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "around area can be changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbourhood (x,y): \n",
    "    around_area = 8\n",
    "    x_Upper_left = x-around_area\n",
    "    y_Upper_left = y-around_area\n",
    "    \n",
    "    x_Lower_right = x+around_area\n",
    "    y_Lower_right = y+around_area\n",
    "    \n",
    "    return x_Upper_left,y_Upper_left,x_Lower_right,y_Lower_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Upper_left,y_Upper_left,x_Lower_right,y_Lower_right = get_neighbourhood (round(kp1[0].pt[0]),round(kp1[0].pt[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cropImg = image1[x_Upper_left:x_Lower_right, y_Upper_left:y_Lower_right]\n",
    "plt.imshow(cropImg)#拼接显示为gray\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_landmark_read_result = pd.read_csv(source_image_landmarks[0])\n",
    "target_landmark_read_result = pd.read_csv(target_image_landmarks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n",
      "(16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img1 = cv2.imread(imgname1)\n",
    "height1, width1, channels = img1.shape\n",
    "img2 = cv2.imread(imgname2)\n",
    "height2, width2, channels = img2.shape\n",
    "\n",
    "source_cropImg_set = []\n",
    "target_cropImg_set = []\n",
    "for source_X, \\\n",
    "    source_Y ,\\\n",
    "    target_X,\\\n",
    "    target_Y in zip(source_landmark_read_result['X'],source_landmark_read_result['Y'],target_landmark_read_result['X'],target_landmark_read_result['Y']):\n",
    "    \n",
    "    source_x_Upper_left,source_y_Upper_left,source_x_Lower_right,source_y_Lower_right = get_neighbourhood (round(source_X),round(source_Y))\n",
    "    target_x_Upper_left,target_y_Upper_left,target_x_Lower_right,target_y_Lower_right = get_neighbourhood (round(target_X),round(target_Y))\n",
    "    \n",
    "    source_cropImg = img1[source_y_Upper_left:source_y_Lower_right, source_x_Upper_left:source_x_Lower_right]\n",
    "    target_cropImg = img2[target_y_Upper_left:target_y_Lower_right, target_x_Upper_left:target_x_Lower_right]\n",
    "    \n",
    "    # height, width, channels = source_cropImg.shape\n",
    "    # print (source_x_Upper_left,source_x_Lower_right, source_y_Upper_left,source_y_Lower_right)\n",
    "    print(source_cropImg.shape)\n",
    "    source_cropImg_set.append(source_cropImg)\n",
    "    target_cropImg_set.append(target_cropImg)\n",
    "    ###### toDo use the two to make  CNN if they are the pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "source_trainloader = torch.utils.data.DataLoader(source_cropImg_set, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "target_trainloader = torch.utils.data.DataLoader(target_cropImg_set, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matchNet(\n",
       "  (conv_0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_1): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool_4): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleNeck): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (fc_1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = matchNet()\n",
    "labels = 1\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.DataParallel(net, list(range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n",
      "tensor([1.], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0.], device='cuda:0')\n",
      "27.63102149963379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-770fb57cb832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# characters to replace unicode characters with.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    for source,target in zip(source_trainloader, target_trainloader):\n",
    "        # 置换 tensor from NWHC to NCWH\n",
    "        b_size = 1\n",
    "        label = torch.full((b_size,), labels,  device=device)\n",
    "        \n",
    "        \n",
    "        source=source.permute(0, 3, 1, 2)\n",
    "        target=target.permute(0, 3, 1, 2)\n",
    "        source = source.float()\n",
    "        target = target.float()\n",
    "        outputs = net(source,target).view(-1)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #################################\n",
    "        # Here wantna to train the \n",
    "        ##################################\n",
    "        j = 0\n",
    "        for target_false in target_trainloader:\n",
    "            # if the same one \n",
    "            if j == i :\n",
    "                outputs = net(source,target).view(-1)\n",
    "                loss = criterion(outputs, label)\n",
    "                \n",
    "            else:\n",
    "                # not same\n",
    "                labels_false = 0\n",
    "                label_false = torch.full((b_size,), labels_false,  device=device)\n",
    "                target_false=target_false.permute(0, 3, 1, 2)\n",
    "                target_false = target_false.float()\n",
    "                outputs = net(source,target_false).view(-1)\n",
    "                loss = criterion(outputs, label_false)\n",
    "                print(outputs)\n",
    "                print(label_false)\n",
    "                print(loss.item())\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            j = j+1\n",
    "            \n",
    "        \n",
    "        \n",
    "        i = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the main train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train is for training each pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training.........\n",
      "epoch ,  0\n",
      "The loss is 27.63102149963379\n",
      "The loss is 27.63102149963379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-14e8f369e980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print ('begin training.........')\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    print ('epoch , ',epoch)\n",
    "    \n",
    "    num = 0\n",
    "    for source,target, s_landmark,t_landmark in zip(source_image_array[:180], target_image_array[:180], source_image_landmarks[:180] ,target_image_landmarks[:180]):\n",
    "        imgname1 = source\n",
    "        imgname2 = target\n",
    "        source_landmark_read_result = pd.read_csv(s_landmark)\n",
    "        target_landmark_read_result = pd.read_csv(t_landmark)\n",
    "\n",
    "        labels = 1\n",
    "        \n",
    "        num = num + 1\n",
    "\n",
    "\n",
    "        # read the image and put the small regin in the train loader\n",
    "        img1 = cv2.imread(imgname1)\n",
    "        height1, width1, channels = img1.shape\n",
    "        img2 = cv2.imread(imgname2)\n",
    "        height2, width2, channels = img2.shape\n",
    "\n",
    "        source_cropImg_set = []\n",
    "        target_cropImg_set = []\n",
    "        for source_X, \\\n",
    "            source_Y ,\\\n",
    "            target_X,\\\n",
    "            target_Y in zip(source_landmark_read_result['X'],source_landmark_read_result['Y'],target_landmark_read_result['X'],target_landmark_read_result['Y']):\n",
    "\n",
    "            source_x_Upper_left,source_y_Upper_left,source_x_Lower_right,source_y_Lower_right = get_neighbourhood (round(source_X),round(source_Y))\n",
    "            target_x_Upper_left,target_y_Upper_left,target_x_Lower_right,target_y_Lower_right = get_neighbourhood (round(target_X),round(target_Y))\n",
    "\n",
    "            source_cropImg = img1[source_y_Upper_left:source_y_Lower_right, source_x_Upper_left:source_x_Lower_right]\n",
    "            target_cropImg = img2[target_y_Upper_left:target_y_Lower_right, target_x_Upper_left:target_x_Lower_right]\n",
    "\n",
    "            # height, width, channels = source_cropImg.shape\n",
    "            # print (source_x_Upper_left,source_x_Lower_right, source_y_Upper_left,source_y_Lower_right)\n",
    "            #\n",
    "            source_cropImg_set.append(source_cropImg)\n",
    "            target_cropImg_set.append(target_cropImg)\n",
    "            ###### toDo use the two to make  CNN if they are the pairs\n",
    "        ############# put the patch into the train loader\n",
    "        transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        source_trainloader = torch.utils.data.DataLoader(source_cropImg_set, batch_size=1,shuffle=True, num_workers=1)\n",
    "        target_trainloader = torch.utils.data.DataLoader(target_cropImg_set, batch_size=1,shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for source,target in zip(source_trainloader, target_trainloader):\n",
    "            # 置换 tensor from NWHC to NCWH\n",
    "            b_size = 1\n",
    "            label = torch.full((b_size,), labels,  device=device)\n",
    "\n",
    "\n",
    "            source=source.permute(0, 3, 1, 2)\n",
    "            target=target.permute(0, 3, 1, 2)\n",
    "            source = source.float()\n",
    "            target = target.float()\n",
    "            outputs = net(source,target)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #################################\n",
    "            # Here wantna to train the \n",
    "            ##################################\n",
    "            j = 0\n",
    "            for target_false in target_trainloader:\n",
    "                # if the same one \n",
    "                if j == i :\n",
    "                    outputs = net(source,target)\n",
    "                    loss = criterion(outputs, label)\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    # not same\n",
    "                    labels_false = 0\n",
    "                    label_false = torch.full((b_size,), labels_false,  device=device)\n",
    "                    target_false=target_false.permute(0, 3, 1, 2)\n",
    "                    target_false = target_false.float()\n",
    "                    outputs = net(source,target_false)\n",
    "                    loss = criterion(outputs, label_false)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                j = j+1\n",
    "\n",
    "\n",
    "            \n",
    "            print('The loss is',loss.item())\n",
    "            i = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-c62dfe4f7ee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maaa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_image_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmark/COAD_01/scale-25pc/S3.csv\n",
      "landmark/COAD_01/scale-25pc/S6.csv\n",
      "landmark/COAD_01/scale-25pc/S7.csv\n",
      "landmark/COAD_01/scale-25pc/S6.csv\n",
      "landmark/COAD_01/scale-25pc/S7.csv\n",
      "landmark/COAD_01/scale-25pc/S7.csv\n",
      "landmark/COAD_02/scale-25pc/S3.csv\n",
      "landmark/COAD_02/scale-25pc/S6.csv\n",
      "landmark/COAD_02/scale-25pc/S7.csv\n",
      "landmark/COAD_02/scale-25pc/S6.csv\n",
      "landmark/COAD_02/scale-25pc/S7.csv\n",
      "landmark/COAD_02/scale-25pc/S7.csv\n",
      "landmark/COAD_03/scale-25pc/S5.csv\n",
      "landmark/COAD_04/scale-25pc/S5.csv\n",
      "landmark/COAD_05/scale-25pc/S5-v1.csv\n",
      "landmark/COAD_05/scale-25pc/S6.csv\n",
      "landmark/COAD_05/scale-25pc/S7.csv\n",
      "landmark/COAD_05/scale-25pc/S6.csv\n",
      "landmark/COAD_05/scale-25pc/S7.csv\n",
      "landmark/COAD_05/scale-25pc/S7.csv\n",
      "landmark/COAD_06/scale-25pc/S5.csv\n",
      "landmark/COAD_06/scale-25pc/S7.csv\n",
      "landmark/COAD_06/scale-25pc/S7.csv\n",
      "landmark/COAD_07/scale-25pc/S5.csv\n",
      "landmark/COAD_07/scale-25pc/S7.csv\n",
      "landmark/COAD_07/scale-25pc/S7.csv\n",
      "landmark/COAD_08/scale-25pc/S3.csv\n",
      "landmark/COAD_08/scale-25pc/S6.csv\n",
      "landmark/COAD_08/scale-25pc/S7.csv\n",
      "landmark/COAD_08/scale-25pc/S6.csv\n",
      "landmark/COAD_08/scale-25pc/S7.csv\n",
      "landmark/COAD_08/scale-25pc/S7.csv\n",
      "landmark/COAD_09/scale-25pc/S2.csv\n",
      "landmark/COAD_09/scale-25pc/S5.csv\n",
      "landmark/COAD_09/scale-25pc/S6.csv\n",
      "landmark/COAD_09/scale-25pc/S5.csv\n",
      "landmark/COAD_09/scale-25pc/S6.csv\n",
      "landmark/COAD_09/scale-25pc/S6.csv\n",
      "landmark/COAD_10/scale-25pc/S4.csv\n",
      "landmark/COAD_10/scale-25pc/S6.csv\n",
      "landmark/COAD_10/scale-25pc/S7.csv\n",
      "landmark/COAD_10/scale-25pc/S6.csv\n",
      "landmark/COAD_10/scale-25pc/S7.csv\n",
      "landmark/COAD_10/scale-25pc/S7.csv\n",
      "landmark/COAD_11/scale-25pc/S2.csv\n",
      "landmark/COAD_11/scale-25pc/S5.csv\n",
      "landmark/COAD_11/scale-25pc/S6.csv\n",
      "landmark/COAD_11/scale-25pc/S5.csv\n",
      "landmark/COAD_11/scale-25pc/S6.csv\n",
      "landmark/COAD_11/scale-25pc/S6.csv\n",
      "landmark/COAD_12/scale-25pc/S2.csv\n",
      "landmark/COAD_12/scale-25pc/S5.csv\n",
      "landmark/COAD_12/scale-25pc/S6.csv\n",
      "landmark/COAD_12/scale-25pc/S5.csv\n",
      "landmark/COAD_12/scale-25pc/S6.csv\n",
      "landmark/COAD_12/scale-25pc/S6.csv\n",
      "landmark/COAD_13/scale-25pc/S5.csv\n",
      "landmark/COAD_13/scale-25pc/S7.csv\n",
      "landmark/COAD_13/scale-25pc/S7.csv\n",
      "landmark/COAD_14/scale-25pc/S5.csv\n",
      "landmark/COAD_15/scale-25pc/S5.csv\n",
      "landmark/COAD_16/scale-25pc/S6.csv\n",
      "landmark/COAD_17/scale-25pc/S2.csv\n",
      "landmark/COAD_17/scale-25pc/S5.csv\n",
      "landmark/COAD_17/scale-25pc/S6.csv\n",
      "landmark/COAD_17/scale-25pc/S5.csv\n",
      "landmark/COAD_17/scale-25pc/S6.csv\n",
      "landmark/COAD_17/scale-25pc/S6.csv\n",
      "landmark/COAD_18/scale-25pc/S5.csv\n",
      "landmark/COAD_18/scale-25pc/S7.csv\n",
      "landmark/COAD_18/scale-25pc/S7.csv\n",
      "landmark/COAD_19/scale-25pc/S3.csv\n",
      "landmark/COAD_19/scale-25pc/S5.csv\n",
      "landmark/COAD_19/scale-25pc/S6.csv\n",
      "landmark/COAD_19/scale-25pc/S8.csv\n",
      "landmark/COAD_19/scale-25pc/S5.csv\n",
      "landmark/COAD_19/scale-25pc/S6.csv\n",
      "landmark/COAD_19/scale-25pc/S8.csv\n",
      "landmark/COAD_19/scale-25pc/S6.csv\n",
      "landmark/COAD_19/scale-25pc/S8.csv\n",
      "landmark/COAD_19/scale-25pc/S8.csv\n",
      "landmark/COAD_20/scale-25pc/S5.csv\n",
      "landmark/COAD_20/scale-25pc/S7.csv\n",
      "landmark/COAD_20/scale-25pc/S7.csv\n",
      "landmark/breast_1/scale-20pc/HER2.csv\n",
      "landmark/breast_2/scale-20pc/HER2.csv\n",
      "landmark/breast_3/scale-20pc/HER2.csv\n",
      "landmark/breast_4/scale-20pc/HER2.csv\n",
      "landmark/breast_5/scale-20pc/HER2.csv\n",
      "landmark/gastric_1/scale-15pc/CD68.csv\n",
      "landmark/gastric_2/scale-15pc/CD68.csv\n",
      "landmark/gastric_3/scale-15pc/CD68.csv\n",
      "landmark/gastric_4/scale-15pc/CD68.csv\n",
      "landmark/gastric_5/scale-15pc/CD68.csv\n",
      "landmark/gastric_5/scale-15pc/EBV.csv\n",
      "landmark/gastric_5/scale-15pc/EBV.csv\n",
      "landmark/gastric_6/scale-15pc/CD68.csv\n",
      "landmark/gastric_6/scale-15pc/EBV.csv\n",
      "landmark/gastric_6/scale-15pc/EBV.csv\n",
      "landmark/gastric_7/scale-15pc/CD68.csv\n",
      "landmark/gastric_8/scale-15pc/CD8.csv\n",
      "landmark/gastric_9/scale-15pc/CD68.csv\n",
      "landmark/kidney_1/scale-25pc/PAS.csv\n",
      "landmark/kidney_2/scale-25pc/PAS.csv\n",
      "landmark/kidney_3/scale-25pc/PAS.csv\n",
      "landmark/kidney_4/scale-25pc/PAS.csv\n",
      "landmark/kidney_5/scale-25pc/PAS.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-Cc10-5-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-Ki67-7-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-proSPC-4-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-He-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-Ki67-7-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-proSPC-4-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-Ki67-7-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-proSPC-4-les2.csv\n",
      "landmark/lung-lesion_2/scale-25pc/29-041-Izd2-w35-proSPC-4-les2.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-Cc10-5-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-He-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-Ki67-7-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-proSPC-4-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-He-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-Ki67-7-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-proSPC-4-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-Ki67-7-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-proSPC-4-les1.csv\n",
      "landmark/lung-lesion_1/scale-50pc/29-041-Izd2-w35-proSPC-4-les1.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-Cc10-5-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-He-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-Ki67-7-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-proSPC-4-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-He-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-Ki67-7-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-proSPC-4-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-Ki67-7-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-proSPC-4-les3.csv\n",
      "landmark/lung-lesion_3/scale-50pc/29-041-Izd2-w35-proSPC-4-les3.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-2-cd31.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_1/scale-100pc/29-039-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-2-cd31.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_2/scale-100pc/29-039-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-2-cd31.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-4-cc10.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_3/scale-100pc/29-040-U-35W-Izd1-6-ki67.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-2-cd31.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-3-Pro-SPC.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-6-ki67.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-4-cc10.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-6-ki67.csv\n",
      "landmark/lung-lobes_4/scale-100pc/29-040-U-35W-Izd2-6-ki67.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_36-CNEU_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_37-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_38-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_40-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_37-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_38-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_40-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_38-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_40-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_1/scale-25pc/s1_40-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_62-ER_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_63-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_64-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_66-CNEU_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_67-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_63-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_64-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_66-CNEU_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_67-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_64-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_66-CNEU_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_67-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_66-CNEU_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_67-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_67-HE_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_68-ER-A4962-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mammary-gland_2/scale-25pc/s2_70-PR_A4926-4L.csv\n",
      "landmark/mice-kidney_1/scale-25pc/3_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/5_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/6_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/8_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/9_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/5_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/6_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/8_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/9_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/6_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/8_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/9_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/8_CD31.csv\n",
      "landmark/mice-kidney_1/scale-25pc/9_PAS.csv\n",
      "landmark/mice-kidney_1/scale-25pc/9_PAS.csv\n",
      "COAD_20/scale-25pc/S7.csv\n",
      "COAD_20/scale-25pc/S5.csv\n",
      "COAD_20/scale-25pc/S7.csv\n",
      "COAD_20/scale-25pc/S7.csv\n",
      "COAD_20/scale-25pc/S2.csv\n",
      "COAD_20/scale-25pc/S5.csv\n",
      "COAD_20/scale-25pc/S7.csv\n",
      "breast_1/scale-20pc/HE.csv\n",
      "breast_1/scale-20pc/HER2.csv\n",
      "breast_1/scale-20pc/HER2.csv\n",
      "breast_1/scale-20pc/HE.csv\n",
      "breast_1/scale-20pc/HER2.csv\n",
      "breast_2/scale-20pc/HE.csv\n",
      "breast_2/scale-20pc/HER2.csv\n",
      "breast_2/scale-20pc/HER2.csv\n",
      "breast_2/scale-20pc/HE.csv\n",
      "breast_2/scale-20pc/HER2.csv\n",
      "breast_3/scale-20pc/HE.csv\n",
      "breast_3/scale-20pc/HER2.csv\n",
      "breast_3/scale-20pc/HER2.csv\n",
      "breast_3/scale-20pc/HE.csv\n",
      "breast_3/scale-20pc/HER2.csv\n",
      "breast_4/scale-20pc/HE.csv\n",
      "breast_4/scale-20pc/HER2.csv\n",
      "breast_4/scale-20pc/HER2.csv\n",
      "breast_4/scale-20pc/HE.csv\n",
      "breast_4/scale-20pc/HER2.csv\n",
      "breast_5/scale-20pc/HE.csv\n",
      "breast_5/scale-20pc/HER2.csv\n",
      "breast_5/scale-20pc/HER2.csv\n",
      "breast_5/scale-20pc/HE.csv\n",
      "breast_5/scale-20pc/HER2.csv\n",
      "gastric_1/scale-15pc/CD4.csv\n",
      "gastric_1/scale-15pc/CD68.csv\n",
      "gastric_1/scale-15pc/CD68.csv\n",
      "gastric_1/scale-15pc/CD4.csv\n",
      "gastric_1/scale-15pc/CD68.csv\n",
      "gastric_2/scale-15pc/CD4.csv\n",
      "gastric_2/scale-15pc/CD68.csv\n",
      "gastric_2/scale-15pc/CD68.csv\n",
      "gastric_2/scale-15pc/CD4.csv\n",
      "gastric_2/scale-15pc/CD68.csv\n",
      "gastric_3/scale-15pc/CD4.csv\n",
      "gastric_3/scale-15pc/CD68.csv\n",
      "gastric_3/scale-15pc/CD68.csv\n",
      "gastric_3/scale-15pc/CD4.csv\n",
      "gastric_3/scale-15pc/CD68.csv\n",
      "gastric_4/scale-15pc/CD4.csv\n",
      "gastric_4/scale-15pc/CD68.csv\n",
      "gastric_4/scale-15pc/CD68.csv\n",
      "gastric_4/scale-15pc/CD4.csv\n",
      "gastric_4/scale-15pc/CD68.csv\n",
      "gastric_5/scale-15pc/CD4.csv\n",
      "gastric_5/scale-15pc/CD68.csv\n",
      "gastric_5/scale-15pc/EBV.csv\n",
      "gastric_5/scale-15pc/CD68.csv\n",
      "gastric_5/scale-15pc/EBV.csv\n",
      "gastric_5/scale-15pc/EBV.csv\n",
      "gastric_5/scale-15pc/CD4.csv\n",
      "gastric_5/scale-15pc/CD68.csv\n",
      "gastric_5/scale-15pc/EBV.csv\n",
      "gastric_6/scale-15pc/CD4.csv\n",
      "gastric_6/scale-15pc/CD68.csv\n",
      "gastric_6/scale-15pc/EBV.csv\n",
      "gastric_6/scale-15pc/CD68.csv\n",
      "gastric_6/scale-15pc/EBV.csv\n",
      "gastric_6/scale-15pc/EBV.csv\n",
      "gastric_6/scale-15pc/CD4.csv\n",
      "gastric_6/scale-15pc/CD68.csv\n",
      "gastric_6/scale-15pc/EBV.csv\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for source,target, s_landmark,t_landmark in zip(source_image_array[:300], target_image_array[:300],source_image_landmarks[:300] ,target_image_landmarks[:300]):\n",
    "    print(s_landmark)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is 0.0\n"
     ]
    }
   ],
   "source": [
    "loss = 0.0\n",
    "print('The loss is',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    }
   ],
   "source": [
    "print (len(target_image_landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
